{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_theory = {\"camb\": {\"extra_args\": {\"lens_potential_accuracy\": 1}}}\n",
    "#info_theory = {\"classy\": {\"extra_args\": {\"non linear\": \"halofit\"}}}\n",
    "\n",
    "# Path to installation\n",
    "modules = \"\"  ## SET!!!\n",
    "\n",
    "# Number of runs over which to average\n",
    "n = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from cobaya.conventions import _likelihood, _theory, _timing, _path_install, _params\n",
    "from cobaya.tools import recursive_update, get_modules\n",
    "from cobaya.cosmo_input import create_input, planck_base_model\n",
    "from cobaya.model import get_model\n",
    "\n",
    "params_test = {\n",
    "    \"omegabh2\": 0.022383,\n",
    "    \"omegach2\": 0.12011,\n",
    "    \"H0\": 67.32,\n",
    "    \"logA\": 3.0448,\n",
    "    \"ns\": 0.96605,\n",
    "    \"tau\": 0.0543}\n",
    "\n",
    "info = create_input(planck_names=True, theory=list(info_theory)[0], **planck_base_model)\n",
    "info[_params][\"H0\"] = {\"prior\": {\"min\": 0, \"max\": 100}}\n",
    "for p in list(info[_params]):\n",
    "    if p.startswith(\"theta\") or p.startswith(\"cosmomc\"):\n",
    "        info[_params].pop(p)\n",
    "info = recursive_update(info, {_theory: info_theory})\n",
    "\n",
    "# Constrain to only:\n",
    "only = []\n",
    "only_startswith = []\n",
    "only_contains = []\n",
    "\n",
    "# Exclude\n",
    "non_startswith = [\n",
    "    # Ignore non-cosmo and generic likes\n",
    "    \"one\", \"gaussian_mixture\", \"_\", \".\",\n",
    "]\n",
    "non_contains = [\n",
    "    # EXCLUDE EITHER Planck 2015 or 2018 (memory errors)\n",
    "    \"planck_2015\",\n",
    "    # EXCLUDE EITHER Planck 2018 CamSpec or plik (incompatible priors and parameter names)\n",
    "    \"plik\",\n",
    "]\n",
    "\n",
    "# For Planck, select either TT or TTTEEE\n",
    "select = \"TT\"\n",
    "if select == \"TT\":\n",
    "    non_contains += [\"TTTEEE\"]\n",
    "elif select == \"TTTEEE\":\n",
    "    only_contains += [\"TTTEEE\"]\n",
    "\n",
    "# NB: It's possible that DES makes everything else slower, since it adds many more\n",
    "# redshifts to the computation, so there are many more redshifts to select the\n",
    "# required e.g. H(z) from, making e.g. SN and BAO likes slower (longer theory code request)\n",
    "#non_contains += [\"des\"]\n",
    "\n",
    "likelihoods = sorted([\n",
    "    like for like in get_modules(\"likelihood\") if\n",
    "    (any([like.startswith(s) for s in only_startswith]) if only_startswith else True) and \n",
    "    not any([like.startswith(s) for s in non_startswith]) and\n",
    "    (any([(s in like) for s in only_contains]) if only_contains else True) and\n",
    "    not any([(s in like) for s in non_contains]) and\n",
    "    (like in only if only else True)])\n",
    "\n",
    "info[_likelihood] = {l:None for l in likelihoods}\n",
    "\n",
    "info[\"debug\"] = False\n",
    "\n",
    "# No fsigma8 in classy!\n",
    "if list(info_theory)[0] == \"classy\":\n",
    "    info[_likelihood].pop(\"sdss_dr12_consensus_final\")\n",
    "    info[_likelihood].pop(\"sdss_dr12_consensus_full_shape\")\n",
    "\n",
    "print(\"\\n\".join(likelihoods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info[_timing] = True\n",
    "info[_path_install] = modules\n",
    "model = get_model(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    point = dict(zip(model.parameterization.sampled_params(), model.prior.sample(ignore_external=True)[0]))\n",
    "    point.update(params_test)\n",
    "    model.loglike(point, cached=False)\n",
    "    print(\"%d%%\"%(100*i/n), end=\" \")\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame(columns=[\"time\", \"time_std\", \"speed-\", \"speed\", \"speed+\", \"old speed\"], index=likelihoods)\n",
    "for name in [_theory] + list(model.likelihood):\n",
    "    like = model.likelihood[name]\n",
    "    df.at[name, \"time\"] = like.time_avg\n",
    "    df.at[name, \"time_std\"] = like.time_std\n",
    "    df.at[name, \"speed-\"] = 1/(like.time_avg+like.time_std) if like.time_std else 0\n",
    "    df.at[name, \"speed\"] = 1/like.time_avg\n",
    "    df.at[name, \"speed+\"] = 1/(like.time_avg-like.time_std) if like.time_std else 0\n",
    "    df.at[name, \"time_std\"] = like.time_std\n",
    "    df.at[name, \"old speed\"] = like.speed\n",
    "    df.at[name, \"factor\"] = like.speed*like.time_avg\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
